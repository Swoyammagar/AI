{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abMIXs4bPGlh",
        "outputId": "b41e5751-1ca5-4190-d86a-a7b7a361cbbe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1 Implementation from Scratch Step - by - Step Guide:\n",
        "\n",
        "3.1.1 Step -1- Data Understanding, Analysis and Preparations:\n",
        "\n",
        "In this step we will read the data, understand the data, perform some basic data cleaning, and store everything\n",
        "in the matrix as shown below.\n",
        "\n",
        "• Requirements:\n",
        "\n",
        "Dataset → student.csv\n",
        "\n",
        "• Decision Process:\n",
        "\n",
        "In this step we will define the objective of the task.\n",
        "\n",
        "– Objective of the Task -\n",
        "To Predict the marks obtained in writing based on the marks of Math and Reading.\n",
        "• To - Do - 1:\n",
        "1. Read and Observe the Dataset.\n",
        "2. Print top(5) and bottom(5) of the dataset {Hint: pd.head and pd.tail}.\n",
        "3. Print the Information of Datasets. {Hint: pd.info}.\n",
        "4. Gather the Descriptive info about the Dataset. {Hint: pd.describe}\n",
        "5. Split your data into Feature (X) and Label (Y)."
      ],
      "metadata": {
        "id": "Wz3aZQl2PhtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df= pd.read_csv('/content/drive/MyDrive/AI/Resources/Week5/student.csv')\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Kmdwd0rUP1_o",
        "outputId": "9f8a4bed-db68-4af6-e394-135cbca61d26"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Math  Reading  Writing\n",
              "0    48       68       63\n",
              "1    62       81       72\n",
              "2    79       80       78\n",
              "3    76       83       79\n",
              "4    59       64       62"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90605e30-0fe0-4874-812e-1d6a37f7aed7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Math</th>\n",
              "      <th>Reading</th>\n",
              "      <th>Writing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>48</td>\n",
              "      <td>68</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>62</td>\n",
              "      <td>81</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>79</td>\n",
              "      <td>80</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>76</td>\n",
              "      <td>83</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59</td>\n",
              "      <td>64</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90605e30-0fe0-4874-812e-1d6a37f7aed7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-90605e30-0fe0-4874-812e-1d6a37f7aed7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-90605e30-0fe0-4874-812e-1d6a37f7aed7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a1fb6727-bbe2-4d39-8389-24764df1ab5b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a1fb6727-bbe2-4d39-8389-24764df1ab5b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a1fb6727-bbe2-4d39-8389-24764df1ab5b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"Math\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 13,\n        \"max\": 100,\n        \"num_unique_values\": 75,\n        \"samples\": [\n          59,\n          34,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Reading\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 19,\n        \"max\": 100,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          64,\n          45,\n          52\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Writing\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 14,\n        \"max\": 100,\n        \"num_unique_values\": 76,\n        \"samples\": [\n          62,\n          91,\n          64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oKDog5ioQK7u",
        "outputId": "b3cb42a9-cc43-43e5-80cf-d09669882682"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Math  Reading  Writing\n",
              "995    72       74       70\n",
              "996    73       86       90\n",
              "997    89       87       94\n",
              "998    83       82       78\n",
              "999    66       66       72"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90892095-ea82-484e-a5be-c58c1e44f8f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Math</th>\n",
              "      <th>Reading</th>\n",
              "      <th>Writing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>72</td>\n",
              "      <td>74</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>73</td>\n",
              "      <td>86</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>89</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>83</td>\n",
              "      <td>82</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>66</td>\n",
              "      <td>66</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90892095-ea82-484e-a5be-c58c1e44f8f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-90892095-ea82-484e-a5be-c58c1e44f8f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-90892095-ea82-484e-a5be-c58c1e44f8f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4095339b-8945-466b-887f-ae6c62b888e9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4095339b-8945-466b-887f-ae6c62b888e9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4095339b-8945-466b-887f-ae6c62b888e9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Math\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 66,\n        \"max\": 89,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          73,\n          66,\n          89\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Reading\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 66,\n        \"max\": 87,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          86,\n          66,\n          87\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Writing\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 70,\n        \"max\": 94,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          90,\n          72,\n          94\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lqUZ_q5QYae",
        "outputId": "3e4121c0-8933-40fb-81b5-493e60f9a136"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype\n",
            "---  ------   --------------  -----\n",
            " 0   Math     1000 non-null   int64\n",
            " 1   Reading  1000 non-null   int64\n",
            " 2   Writing  1000 non-null   int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 23.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "xYH8BYfEQfPm",
        "outputId": "291e43f8-74a1-4d33-d4cf-6677c0753589"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Math      Reading      Writing\n",
              "count  1000.000000  1000.000000  1000.000000\n",
              "mean     67.290000    69.872000    68.616000\n",
              "std      15.085008    14.657027    15.241287\n",
              "min      13.000000    19.000000    14.000000\n",
              "25%      58.000000    60.750000    58.000000\n",
              "50%      68.000000    70.000000    69.500000\n",
              "75%      78.000000    81.000000    79.000000\n",
              "max     100.000000   100.000000   100.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e3835ff-60b4-4b7f-9fe8-aab917d2c56d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Math</th>\n",
              "      <th>Reading</th>\n",
              "      <th>Writing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>67.290000</td>\n",
              "      <td>69.872000</td>\n",
              "      <td>68.616000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>15.085008</td>\n",
              "      <td>14.657027</td>\n",
              "      <td>15.241287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>13.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>58.000000</td>\n",
              "      <td>60.750000</td>\n",
              "      <td>58.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>68.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>69.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>78.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>79.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e3835ff-60b4-4b7f-9fe8-aab917d2c56d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5e3835ff-60b4-4b7f-9fe8-aab917d2c56d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5e3835ff-60b4-4b7f-9fe8-aab917d2c56d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d3a8ee32-f3b0-4770-8e5d-9178f195b4b3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d3a8ee32-f3b0-4770-8e5d-9178f195b4b3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d3a8ee32-f3b0-4770-8e5d-9178f195b4b3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Math\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 334.70993839737343,\n        \"min\": 13.0,\n        \"max\": 1000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          67.29,\n          68.0,\n          1000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Reading\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 333.8589622553041,\n        \"min\": 14.65702713528377,\n        \"max\": 1000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          69.872,\n          70.0,\n          1000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Writing\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 334.45996524707175,\n        \"min\": 14.0,\n        \"max\": 1000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          68.616,\n          69.5,\n          1000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['Math', 'Reading']]  # Independent variables\n",
        "Y = df['Writing']           # Dependent variable\n",
        "\n",
        "print(\"\\nFeatures (X):\")\n",
        "print(X.head())\n",
        "\n",
        "print(\"\\nLabels (Y):\")\n",
        "print(Y.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NVrwmnPQjE-",
        "outputId": "dc92385b-1279-443b-b69f-3fb84a671a99"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Features (X):\n",
            "   Math  Reading\n",
            "0    48       68\n",
            "1    62       81\n",
            "2    79       80\n",
            "3    76       83\n",
            "4    59       64\n",
            "\n",
            "Labels (Y):\n",
            "0    63\n",
            "1    72\n",
            "2    78\n",
            "3    79\n",
            "4    62\n",
            "Name: Writing, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "• To - Do - 2:\n",
        "1. To make the task easier - let’s assume there is no bias or intercept.\n",
        "2. Create the following matrices:\n",
        "\n",
        "Y = WTXW =\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "w1\n",
        "w2\n",
        ".\n",
        ".\n",
        ".\n",
        "wd\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ", where W ∈ R\n",
        "d\n",
        "\n",
        "X =\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x1,1 x1,2 · · · x1,n\n",
        "x2,1 x2,2 · · · x2,n\n",
        ".\n",
        ".\n",
        ".\n",
        ".\n",
        ".\n",
        ".\n",
        ".\n",
        ".\n",
        ".\n",
        ".\n",
        ".\n",
        ".\n",
        "xd,1 xd,2 · · · xd,n\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ", where X ∈ R\n",
        "d×n\n",
        "\n",
        "Y =\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y1\n",
        "y2\n",
        ".\n",
        ".\n",
        ".\n",
        "yn\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ", where Y ∈ R\n",
        "n\n",
        "\n",
        "3. Note: The feature matrix described above does not include a column of 1s, as it assumes the\n",
        "absence of a bias term in the model."
      ],
      "metadata": {
        "id": "S7dMbdusQ6mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.values.T  # Transpose to shape d x n\n",
        "print(\"\\nFeature Matrix X (d x n):\")\n",
        "print(X)\n",
        "\n",
        "d = X.shape[0]  # Number of rows\n",
        "W = np.random.rand(d, 1)  # Random initialization\n",
        "print(\"\\nWeight Matrix W (d x 1):\")\n",
        "print(W)\n",
        "\n",
        "Y = Y.values.reshape(-1, 1)  # Reshape to n x 1\n",
        "print(\"\\nTarget Vector Y (n x 1):\")\n",
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcyyGbvkRBZG",
        "outputId": "036c4f20-51a6-4942-97ee-40c79f2edcce"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature Matrix X (d x n):\n",
            "[[48 62 79 ... 89 83 66]\n",
            " [68 81 80 ... 87 82 66]]\n",
            "\n",
            "Weight Matrix W (d x 1):\n",
            "[[0.53269773]\n",
            " [0.60190505]]\n",
            "\n",
            "Target Vector Y (n x 1):\n",
            "[[ 63]\n",
            " [ 72]\n",
            " [ 78]\n",
            " [ 79]\n",
            " [ 62]\n",
            " [ 85]\n",
            " [ 83]\n",
            " [ 41]\n",
            " [ 80]\n",
            " [ 77]\n",
            " [ 64]\n",
            " [ 90]\n",
            " [ 45]\n",
            " [ 77]\n",
            " [ 70]\n",
            " [ 46]\n",
            " [ 76]\n",
            " [ 44]\n",
            " [ 85]\n",
            " [ 72]\n",
            " [ 53]\n",
            " [ 66]\n",
            " [ 75]\n",
            " [ 49]\n",
            " [ 84]\n",
            " [ 83]\n",
            " [ 68]\n",
            " [ 66]\n",
            " [ 77]\n",
            " [ 78]\n",
            " [ 74]\n",
            " [ 83]\n",
            " [ 72]\n",
            " [ 65]\n",
            " [ 46]\n",
            " [ 66]\n",
            " [ 50]\n",
            " [ 79]\n",
            " [ 68]\n",
            " [ 46]\n",
            " [ 86]\n",
            " [ 70]\n",
            " [ 61]\n",
            " [ 53]\n",
            " [ 72]\n",
            " [ 75]\n",
            " [ 50]\n",
            " [ 77]\n",
            " [100]\n",
            " [ 81]\n",
            " [100]\n",
            " [ 87]\n",
            " [ 78]\n",
            " [ 48]\n",
            " [ 50]\n",
            " [ 44]\n",
            " [ 48]\n",
            " [ 43]\n",
            " [ 67]\n",
            " [ 78]\n",
            " [ 58]\n",
            " [ 91]\n",
            " [ 92]\n",
            " [ 78]\n",
            " [ 42]\n",
            " [ 85]\n",
            " [ 73]\n",
            " [ 83]\n",
            " [ 61]\n",
            " [ 58]\n",
            " [ 60]\n",
            " [ 55]\n",
            " [ 48]\n",
            " [ 62]\n",
            " [ 68]\n",
            " [ 59]\n",
            " [ 62]\n",
            " [ 48]\n",
            " [ 74]\n",
            " [ 63]\n",
            " [ 80]\n",
            " [ 79]\n",
            " [ 73]\n",
            " [ 79]\n",
            " [ 45]\n",
            " [ 67]\n",
            " [ 89]\n",
            " [ 77]\n",
            " [ 81]\n",
            " [ 88]\n",
            " [ 53]\n",
            " [ 68]\n",
            " [ 79]\n",
            " [ 77]\n",
            " [ 63]\n",
            " [ 73]\n",
            " [ 60]\n",
            " [ 67]\n",
            " [100]\n",
            " [ 79]\n",
            " [ 26]\n",
            " [ 51]\n",
            " [ 80]\n",
            " [ 57]\n",
            " [ 41]\n",
            " [ 78]\n",
            " [ 68]\n",
            " [ 49]\n",
            " [ 76]\n",
            " [ 41]\n",
            " [ 71]\n",
            " [ 77]\n",
            " [ 89]\n",
            " [ 86]\n",
            " [ 55]\n",
            " [ 80]\n",
            " [ 56]\n",
            " [ 74]\n",
            " [ 85]\n",
            " [ 80]\n",
            " [ 73]\n",
            " [ 74]\n",
            " [ 86]\n",
            " [ 56]\n",
            " [ 53]\n",
            " [ 44]\n",
            " [ 41]\n",
            " [ 59]\n",
            " [ 71]\n",
            " [ 81]\n",
            " [ 74]\n",
            " [ 78]\n",
            " [ 67]\n",
            " [ 53]\n",
            " [ 56]\n",
            " [ 75]\n",
            " [ 82]\n",
            " [ 79]\n",
            " [ 99]\n",
            " [ 76]\n",
            " [ 59]\n",
            " [ 96]\n",
            " [ 75]\n",
            " [ 61]\n",
            " [ 56]\n",
            " [ 88]\n",
            " [ 65]\n",
            " [100]\n",
            " [ 79]\n",
            " [ 55]\n",
            " [ 61]\n",
            " [ 83]\n",
            " [ 74]\n",
            " [ 59]\n",
            " [ 54]\n",
            " [ 47]\n",
            " [ 82]\n",
            " [ 74]\n",
            " [ 59]\n",
            " [ 74]\n",
            " [ 84]\n",
            " [ 59]\n",
            " [ 43]\n",
            " [ 65]\n",
            " [ 61]\n",
            " [ 78]\n",
            " [ 84]\n",
            " [ 73]\n",
            " [ 73]\n",
            " [ 92]\n",
            " [ 63]\n",
            " [ 72]\n",
            " [ 61]\n",
            " [ 59]\n",
            " [ 70]\n",
            " [ 87]\n",
            " [ 78]\n",
            " [ 65]\n",
            " [ 73]\n",
            " [ 62]\n",
            " [ 69]\n",
            " [ 55]\n",
            " [ 73]\n",
            " [ 63]\n",
            " [ 67]\n",
            " [ 86]\n",
            " [ 78]\n",
            " [ 85]\n",
            " [ 83]\n",
            " [ 80]\n",
            " [ 60]\n",
            " [ 90]\n",
            " [ 56]\n",
            " [ 70]\n",
            " [ 55]\n",
            " [ 80]\n",
            " [ 82]\n",
            " [ 60]\n",
            " [ 78]\n",
            " [ 76]\n",
            " [ 94]\n",
            " [ 75]\n",
            " [ 68]\n",
            " [ 71]\n",
            " [ 85]\n",
            " [ 46]\n",
            " [ 58]\n",
            " [ 46]\n",
            " [ 84]\n",
            " [ 58]\n",
            " [ 57]\n",
            " [ 59]\n",
            " [ 77]\n",
            " [ 63]\n",
            " [ 68]\n",
            " [ 99]\n",
            " [ 48]\n",
            " [ 91]\n",
            " [ 57]\n",
            " [ 80]\n",
            " [ 46]\n",
            " [ 75]\n",
            " [ 59]\n",
            " [ 87]\n",
            " [ 82]\n",
            " [ 79]\n",
            " [ 66]\n",
            " [ 68]\n",
            " [ 66]\n",
            " [ 61]\n",
            " [ 66]\n",
            " [ 63]\n",
            " [ 72]\n",
            " [ 73]\n",
            " [ 77]\n",
            " [ 84]\n",
            " [ 83]\n",
            " [ 42]\n",
            " [ 72]\n",
            " [ 76]\n",
            " [ 76]\n",
            " [ 39]\n",
            " [ 74]\n",
            " [ 43]\n",
            " [ 63]\n",
            " [ 74]\n",
            " [ 52]\n",
            " [ 31]\n",
            " [ 65]\n",
            " [ 45]\n",
            " [ 87]\n",
            " [ 63]\n",
            " [ 51]\n",
            " [ 82]\n",
            " [ 86]\n",
            " [ 76]\n",
            " [ 27]\n",
            " [ 70]\n",
            " [ 79]\n",
            " [ 66]\n",
            " [ 61]\n",
            " [ 62]\n",
            " [ 47]\n",
            " [ 17]\n",
            " [ 65]\n",
            " [ 76]\n",
            " [ 75]\n",
            " [ 66]\n",
            " [ 59]\n",
            " [ 61]\n",
            " [ 93]\n",
            " [ 40]\n",
            " [ 66]\n",
            " [ 43]\n",
            " [ 71]\n",
            " [ 64]\n",
            " [ 55]\n",
            " [ 86]\n",
            " [ 65]\n",
            " [ 70]\n",
            " [ 65]\n",
            " [ 53]\n",
            " [ 49]\n",
            " [ 67]\n",
            " [ 76]\n",
            " [ 95]\n",
            " [ 76]\n",
            " [ 48]\n",
            " [ 60]\n",
            " [ 53]\n",
            " [ 69]\n",
            " [ 78]\n",
            " [ 62]\n",
            " [ 66]\n",
            " [ 51]\n",
            " [ 52]\n",
            " [ 46]\n",
            " [ 42]\n",
            " [ 77]\n",
            " [ 57]\n",
            " [100]\n",
            " [ 84]\n",
            " [ 68]\n",
            " [ 48]\n",
            " [ 72]\n",
            " [ 50]\n",
            " [ 72]\n",
            " [ 55]\n",
            " [ 72]\n",
            " [ 77]\n",
            " [ 56]\n",
            " [ 94]\n",
            " [ 67]\n",
            " [ 82]\n",
            " [ 75]\n",
            " [ 80]\n",
            " [ 60]\n",
            " [ 73]\n",
            " [ 74]\n",
            " [ 62]\n",
            " [ 53]\n",
            " [ 69]\n",
            " [ 75]\n",
            " [ 60]\n",
            " [ 58]\n",
            " [ 71]\n",
            " [ 87]\n",
            " [ 74]\n",
            " [ 87]\n",
            " [ 73]\n",
            " [ 78]\n",
            " [ 76]\n",
            " [ 74]\n",
            " [ 55]\n",
            " [ 94]\n",
            " [ 71]\n",
            " [ 76]\n",
            " [ 59]\n",
            " [ 91]\n",
            " [ 57]\n",
            " [ 83]\n",
            " [ 59]\n",
            " [ 93]\n",
            " [ 64]\n",
            " [ 58]\n",
            " [ 79]\n",
            " [ 96]\n",
            " [ 76]\n",
            " [ 64]\n",
            " [ 70]\n",
            " [ 80]\n",
            " [ 33]\n",
            " [ 95]\n",
            " [ 64]\n",
            " [ 92]\n",
            " [ 34]\n",
            " [ 72]\n",
            " [ 81]\n",
            " [ 57]\n",
            " [ 79]\n",
            " [ 84]\n",
            " [ 82]\n",
            " [ 54]\n",
            " [ 45]\n",
            " [ 54]\n",
            " [ 62]\n",
            " [ 49]\n",
            " [ 74]\n",
            " [ 59]\n",
            " [ 63]\n",
            " [ 83]\n",
            " [ 62]\n",
            " [ 72]\n",
            " [ 72]\n",
            " [ 65]\n",
            " [ 65]\n",
            " [ 54]\n",
            " [ 78]\n",
            " [ 82]\n",
            " [ 85]\n",
            " [ 74]\n",
            " [ 83]\n",
            " [ 71]\n",
            " [ 83]\n",
            " [ 77]\n",
            " [ 66]\n",
            " [ 75]\n",
            " [ 52]\n",
            " [ 68]\n",
            " [ 84]\n",
            " [ 67]\n",
            " [ 70]\n",
            " [ 41]\n",
            " [ 91]\n",
            " [ 46]\n",
            " [ 58]\n",
            " [ 67]\n",
            " [ 70]\n",
            " [ 83]\n",
            " [ 64]\n",
            " [100]\n",
            " [ 49]\n",
            " [ 77]\n",
            " [ 57]\n",
            " [ 67]\n",
            " [ 80]\n",
            " [ 74]\n",
            " [ 41]\n",
            " [ 67]\n",
            " [ 59]\n",
            " [ 86]\n",
            " [ 88]\n",
            " [ 57]\n",
            " [ 80]\n",
            " [ 58]\n",
            " [ 52]\n",
            " [ 31]\n",
            " [ 84]\n",
            " [ 97]\n",
            " [ 71]\n",
            " [ 62]\n",
            " [ 58]\n",
            " [ 71]\n",
            " [ 41]\n",
            " [ 66]\n",
            " [100]\n",
            " [ 51]\n",
            " [ 35]\n",
            " [ 81]\n",
            " [ 94]\n",
            " [ 72]\n",
            " [ 38]\n",
            " [ 82]\n",
            " [ 79]\n",
            " [ 55]\n",
            " [ 75]\n",
            " [ 90]\n",
            " [ 95]\n",
            " [ 65]\n",
            " [ 39]\n",
            " [ 85]\n",
            " [ 86]\n",
            " [ 54]\n",
            " [ 93]\n",
            " [ 69]\n",
            " [ 84]\n",
            " [ 78]\n",
            " [ 58]\n",
            " [ 73]\n",
            " [ 60]\n",
            " [ 44]\n",
            " [ 67]\n",
            " [ 69]\n",
            " [ 55]\n",
            " [ 59]\n",
            " [ 88]\n",
            " [ 42]\n",
            " [ 78]\n",
            " [ 84]\n",
            " [ 68]\n",
            " [ 66]\n",
            " [ 51]\n",
            " [ 43]\n",
            " [ 38]\n",
            " [ 69]\n",
            " [ 90]\n",
            " [ 73]\n",
            " [ 67]\n",
            " [ 57]\n",
            " [ 81]\n",
            " [ 63]\n",
            " [ 80]\n",
            " [ 78]\n",
            " [ 65]\n",
            " [ 74]\n",
            " [ 80]\n",
            " [ 60]\n",
            " [ 60]\n",
            " [ 63]\n",
            " [ 64]\n",
            " [ 72]\n",
            " [ 51]\n",
            " [ 71]\n",
            " [ 63]\n",
            " [ 82]\n",
            " [ 76]\n",
            " [ 39]\n",
            " [ 79]\n",
            " [ 48]\n",
            " [ 70]\n",
            " [ 90]\n",
            " [ 73]\n",
            " [ 58]\n",
            " [100]\n",
            " [ 80]\n",
            " [ 75]\n",
            " [ 72]\n",
            " [ 79]\n",
            " [ 52]\n",
            " [ 56]\n",
            " [ 65]\n",
            " [ 45]\n",
            " [ 59]\n",
            " [ 61]\n",
            " [ 47]\n",
            " [ 62]\n",
            " [ 83]\n",
            " [ 90]\n",
            " [ 76]\n",
            " [ 72]\n",
            " [ 69]\n",
            " [ 57]\n",
            " [ 56]\n",
            " [ 40]\n",
            " [ 79]\n",
            " [ 48]\n",
            " [ 57]\n",
            " [ 47]\n",
            " [ 78]\n",
            " [ 45]\n",
            " [ 74]\n",
            " [ 69]\n",
            " [ 59]\n",
            " [ 85]\n",
            " [ 45]\n",
            " [ 54]\n",
            " [ 72]\n",
            " [ 74]\n",
            " [ 75]\n",
            " [ 55]\n",
            " [ 49]\n",
            " [ 53]\n",
            " [ 83]\n",
            " [ 22]\n",
            " [100]\n",
            " [ 67]\n",
            " [ 83]\n",
            " [ 46]\n",
            " [ 43]\n",
            " [ 74]\n",
            " [ 64]\n",
            " [ 35]\n",
            " [ 67]\n",
            " [ 87]\n",
            " [ 77]\n",
            " [ 91]\n",
            " [ 74]\n",
            " [ 96]\n",
            " [ 82]\n",
            " [ 78]\n",
            " [ 73]\n",
            " [ 52]\n",
            " [ 91]\n",
            " [ 66]\n",
            " [ 67]\n",
            " [ 71]\n",
            " [ 74]\n",
            " [ 71]\n",
            " [ 61]\n",
            " [ 47]\n",
            " [ 76]\n",
            " [ 85]\n",
            " [ 93]\n",
            " [ 41]\n",
            " [ 81]\n",
            " [ 86]\n",
            " [ 53]\n",
            " [ 91]\n",
            " [ 68]\n",
            " [ 96]\n",
            " [ 48]\n",
            " [ 71]\n",
            " [ 75]\n",
            " [ 72]\n",
            " [ 71]\n",
            " [ 62]\n",
            " [ 67]\n",
            " [ 53]\n",
            " [ 74]\n",
            " [ 63]\n",
            " [ 82]\n",
            " [ 57]\n",
            " [ 69]\n",
            " [ 52]\n",
            " [ 91]\n",
            " [ 73]\n",
            " [ 73]\n",
            " [ 75]\n",
            " [ 36]\n",
            " [ 71]\n",
            " [ 62]\n",
            " [100]\n",
            " [ 50]\n",
            " [ 74]\n",
            " [ 60]\n",
            " [ 75]\n",
            " [ 83]\n",
            " [ 83]\n",
            " [100]\n",
            " [ 67]\n",
            " [ 71]\n",
            " [ 77]\n",
            " [ 67]\n",
            " [ 95]\n",
            " [ 52]\n",
            " [ 71]\n",
            " [ 74]\n",
            " [ 60]\n",
            " [ 67]\n",
            " [ 79]\n",
            " [ 75]\n",
            " [ 95]\n",
            " [ 69]\n",
            " [ 80]\n",
            " [ 48]\n",
            " [ 61]\n",
            " [ 82]\n",
            " [ 39]\n",
            " [ 70]\n",
            " [ 70]\n",
            " [ 69]\n",
            " [ 32]\n",
            " [ 79]\n",
            " [ 53]\n",
            " [ 59]\n",
            " [ 83]\n",
            " [100]\n",
            " [ 80]\n",
            " [ 80]\n",
            " [ 82]\n",
            " [ 56]\n",
            " [ 83]\n",
            " [ 85]\n",
            " [ 88]\n",
            " [ 81]\n",
            " [ 95]\n",
            " [ 63]\n",
            " [ 70]\n",
            " [ 89]\n",
            " [ 59]\n",
            " [ 56]\n",
            " [ 62]\n",
            " [ 95]\n",
            " [ 63]\n",
            " [ 82]\n",
            " [ 69]\n",
            " [ 58]\n",
            " [ 74]\n",
            " [ 66]\n",
            " [ 82]\n",
            " [ 94]\n",
            " [ 70]\n",
            " [ 78]\n",
            " [ 63]\n",
            " [ 91]\n",
            " [ 70]\n",
            " [ 62]\n",
            " [ 79]\n",
            " [ 65]\n",
            " [ 74]\n",
            " [ 56]\n",
            " [ 65]\n",
            " [100]\n",
            " [ 70]\n",
            " [ 66]\n",
            " [ 54]\n",
            " [ 72]\n",
            " [ 90]\n",
            " [ 56]\n",
            " [ 65]\n",
            " [ 50]\n",
            " [ 95]\n",
            " [ 38]\n",
            " [ 76]\n",
            " [ 84]\n",
            " [ 76]\n",
            " [ 55]\n",
            " [ 85]\n",
            " [ 70]\n",
            " [ 73]\n",
            " [ 80]\n",
            " [ 83]\n",
            " [ 53]\n",
            " [ 67]\n",
            " [100]\n",
            " [ 67]\n",
            " [ 44]\n",
            " [ 96]\n",
            " [ 48]\n",
            " [ 77]\n",
            " [100]\n",
            " [ 40]\n",
            " [ 91]\n",
            " [ 55]\n",
            " [ 41]\n",
            " [ 25]\n",
            " [ 63]\n",
            " [ 59]\n",
            " [ 63]\n",
            " [ 77]\n",
            " [ 46]\n",
            " [ 49]\n",
            " [ 46]\n",
            " [ 93]\n",
            " [ 39]\n",
            " [ 58]\n",
            " [ 87]\n",
            " [ 57]\n",
            " [ 77]\n",
            " [100]\n",
            " [ 65]\n",
            " [ 34]\n",
            " [ 87]\n",
            " [ 81]\n",
            " [ 63]\n",
            " [ 69]\n",
            " [ 74]\n",
            " [ 70]\n",
            " [ 93]\n",
            " [ 63]\n",
            " [ 81]\n",
            " [ 81]\n",
            " [ 63]\n",
            " [ 87]\n",
            " [ 76]\n",
            " [ 54]\n",
            " [ 89]\n",
            " [ 63]\n",
            " [ 76]\n",
            " [ 79]\n",
            " [ 75]\n",
            " [ 50]\n",
            " [ 36]\n",
            " [ 82]\n",
            " [ 83]\n",
            " [ 85]\n",
            " [ 82]\n",
            " [ 41]\n",
            " [ 82]\n",
            " [ 45]\n",
            " [ 57]\n",
            " [ 88]\n",
            " [ 81]\n",
            " [ 98]\n",
            " [ 61]\n",
            " [ 95]\n",
            " [ 84]\n",
            " [ 71]\n",
            " [ 52]\n",
            " [ 71]\n",
            " [ 90]\n",
            " [ 75]\n",
            " [ 62]\n",
            " [ 63]\n",
            " [ 86]\n",
            " [ 70]\n",
            " [ 77]\n",
            " [ 68]\n",
            " [ 80]\n",
            " [ 67]\n",
            " [ 67]\n",
            " [ 89]\n",
            " [ 60]\n",
            " [ 79]\n",
            " [ 80]\n",
            " [ 78]\n",
            " [ 70]\n",
            " [ 72]\n",
            " [ 43]\n",
            " [ 14]\n",
            " [ 54]\n",
            " [ 92]\n",
            " [ 71]\n",
            " [ 65]\n",
            " [ 58]\n",
            " [ 56]\n",
            " [ 67]\n",
            " [ 64]\n",
            " [ 81]\n",
            " [ 55]\n",
            " [ 45]\n",
            " [ 86]\n",
            " [ 52]\n",
            " [ 75]\n",
            " [ 81]\n",
            " [ 62]\n",
            " [ 42]\n",
            " [ 21]\n",
            " [ 72]\n",
            " [ 55]\n",
            " [ 66]\n",
            " [ 69]\n",
            " [ 86]\n",
            " [ 67]\n",
            " [ 78]\n",
            " [ 85]\n",
            " [ 66]\n",
            " [ 47]\n",
            " [100]\n",
            " [ 63]\n",
            " [ 62]\n",
            " [ 61]\n",
            " [ 69]\n",
            " [ 57]\n",
            " [ 76]\n",
            " [ 52]\n",
            " [ 47]\n",
            " [ 51]\n",
            " [ 61]\n",
            " [ 45]\n",
            " [ 59]\n",
            " [ 81]\n",
            " [ 65]\n",
            " [ 53]\n",
            " [ 61]\n",
            " [ 90]\n",
            " [ 74]\n",
            " [ 62]\n",
            " [ 67]\n",
            " [ 50]\n",
            " [ 84]\n",
            " [ 70]\n",
            " [ 52]\n",
            " [ 92]\n",
            " [ 65]\n",
            " [ 65]\n",
            " [ 67]\n",
            " [ 72]\n",
            " [ 66]\n",
            " [ 62]\n",
            " [ 99]\n",
            " [ 62]\n",
            " [ 53]\n",
            " [ 57]\n",
            " [ 78]\n",
            " [ 56]\n",
            " [ 87]\n",
            " [ 79]\n",
            " [ 63]\n",
            " [ 87]\n",
            " [ 86]\n",
            " [ 75]\n",
            " [ 70]\n",
            " [ 60]\n",
            " [ 49]\n",
            " [ 41]\n",
            " [ 78]\n",
            " [ 58]\n",
            " [ 75]\n",
            " [ 89]\n",
            " [ 34]\n",
            " [ 60]\n",
            " [ 80]\n",
            " [ 85]\n",
            " [ 73]\n",
            " [ 58]\n",
            " [ 69]\n",
            " [ 74]\n",
            " [ 52]\n",
            " [ 58]\n",
            " [ 79]\n",
            " [ 86]\n",
            " [ 61]\n",
            " [ 68]\n",
            " [ 67]\n",
            " [ 48]\n",
            " [ 65]\n",
            " [ 73]\n",
            " [ 57]\n",
            " [ 73]\n",
            " [ 57]\n",
            " [ 80]\n",
            " [ 85]\n",
            " [ 81]\n",
            " [ 61]\n",
            " [ 69]\n",
            " [100]\n",
            " [ 99]\n",
            " [ 92]\n",
            " [ 72]\n",
            " [ 57]\n",
            " [ 44]\n",
            " [ 59]\n",
            " [ 62]\n",
            " [ 93]\n",
            " [ 64]\n",
            " [ 57]\n",
            " [ 72]\n",
            " [ 40]\n",
            " [ 85]\n",
            " [ 60]\n",
            " [ 83]\n",
            " [ 63]\n",
            " [ 74]\n",
            " [ 44]\n",
            " [ 61]\n",
            " [ 74]\n",
            " [ 68]\n",
            " [ 78]\n",
            " [ 50]\n",
            " [ 70]\n",
            " [ 68]\n",
            " [ 82]\n",
            " [ 46]\n",
            " [ 96]\n",
            " [100]\n",
            " [ 44]\n",
            " [ 41]\n",
            " [ 95]\n",
            " [ 79]\n",
            " [ 67]\n",
            " [ 52]\n",
            " [ 87]\n",
            " [ 75]\n",
            " [ 61]\n",
            " [ 42]\n",
            " [ 60]\n",
            " [ 57]\n",
            " [ 64]\n",
            " [ 52]\n",
            " [ 68]\n",
            " [ 58]\n",
            " [ 93]\n",
            " [ 75]\n",
            " [ 77]\n",
            " [ 66]\n",
            " [ 63]\n",
            " [ 90]\n",
            " [ 43]\n",
            " [ 65]\n",
            " [ 95]\n",
            " [ 86]\n",
            " [ 31]\n",
            " [ 95]\n",
            " [ 52]\n",
            " [ 63]\n",
            " [ 87]\n",
            " [ 70]\n",
            " [ 59]\n",
            " [ 84]\n",
            " [ 79]\n",
            " [ 77]\n",
            " [ 75]\n",
            " [ 66]\n",
            " [ 69]\n",
            " [ 85]\n",
            " [ 63]\n",
            " [ 50]\n",
            " [ 58]\n",
            " [ 80]\n",
            " [ 47]\n",
            " [ 55]\n",
            " [ 61]\n",
            " [ 87]\n",
            " [ 77]\n",
            " [ 54]\n",
            " [ 66]\n",
            " [ 68]\n",
            " [ 54]\n",
            " [ 69]\n",
            " [ 74]\n",
            " [ 81]\n",
            " [ 72]\n",
            " [ 61]\n",
            " [ 76]\n",
            " [ 63]\n",
            " [ 64]\n",
            " [ 73]\n",
            " [ 62]\n",
            " [ 92]\n",
            " [ 69]\n",
            " [ 70]\n",
            " [ 65]\n",
            " [ 53]\n",
            " [ 74]\n",
            " [ 61]\n",
            " [ 80]\n",
            " [ 85]\n",
            " [ 62]\n",
            " [ 80]\n",
            " [ 83]\n",
            " [ 56]\n",
            " [ 76]\n",
            " [ 52]\n",
            " [ 51]\n",
            " [ 74]\n",
            " [ 57]\n",
            " [ 63]\n",
            " [ 61]\n",
            " [ 87]\n",
            " [ 60]\n",
            " [ 54]\n",
            " [ 89]\n",
            " [ 67]\n",
            " [ 56]\n",
            " [ 70]\n",
            " [ 90]\n",
            " [ 94]\n",
            " [ 78]\n",
            " [ 72]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = np.dot(W.T, X)\n",
        "print(\"\\nPredicted Y (using initial W):\")\n",
        "print(Y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAChB9UgTQC9",
        "outputId": "51cace0b-da1e-404d-f202-94cac4a45c76"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted Y (using initial W):\n",
            "[[ 66.49903445  81.78156834  90.23552476  90.4431467   69.95108933\n",
            "   87.31616762  87.84886535  53.39553803  79.44315546  92.76059879\n",
            "   74.55870777  91.32188101  56.31489517  90.09711013  74.62791508\n",
            "   52.58601104  74.69712239  52.86284029  91.99299337  85.09520858\n",
            "   70.06854317  70.08950396  79.02791158  64.85901968  87.98727998\n",
            "   90.39490017  72.75299262  74.97395165  90.62980786  83.44886885\n",
            "   84.16822775  90.9275979   78.63362847  82.01647603  57.17266869\n",
            "   61.75300138  58.5358542   86.29901868  81.29711714  48.8571269\n",
            "   91.25267369  87.89711188  71.94346563  56.66093174  73.42410498\n",
            "   80.09330704  59.06855193  78.63362847 108.13330078  75.43744207\n",
            "  113.46027811  92.45648379  81.78156834  54.66855544  55.13204586\n",
            "   57.72632721  66.13203709  56.19744132  82.54917376  86.04315021\n",
            "   65.06664163  99.05647853 112.25646802  88.31235577  58.90917652\n",
            "  101.7199672   70.76061632 101.09710137  72.33774873  70.06854317\n",
            "   72.93965378  66.94156409  56.59172443  69.88188201  71.08569211\n",
            "   56.40506327  73.35489767  44.27046925  89.9586955   75.87997171\n",
            "   93.03742805  82.84696381  73.70093424  84.16822775  47.39744833\n",
            "   75.27806666  90.71997596  86.43743331  84.83934011  89.30854392\n",
            "   59.46283504  81.76060756  75.29902744  85.28186974  70.62220169\n",
            "   70.89903095  63.4203019   72.01267294 104.93711438  97.71425381\n",
            "   36.23808168  59.06855193  81.9682295   50.75301015  46.3802994\n",
            "   86.43743331  88.82409272  51.52061557  86.368226    48.0685607\n",
            "   73.02982188  85.57965979 100.77202558  94.72568935  51.79744483\n",
            "   86.78346988  59.80887161  82.50092723 100.23932784  89.35679045\n",
            "   76.75870601  90.23552476  89.97965628  82.27234451  51.33395441\n",
            "   54.46093349  39.9879266   61.93966254  86.672341   100.0317059\n",
            "   86.7625091   79.11807967  75.02219818  63.00505801  65.59933936\n",
            "   89.70282702  97.62408571  95.02980436  95.18917977  98.50282001\n",
            "   69.02410849 103.8025116   78.95870426  76.6894987   70.15871127\n",
            "   85.78728173  84.47234275 108.13330078  88.96250735  62.35490643\n",
            "   72.40695605  93.24505     78.95870426  67.33584719  69.74346738\n",
            "   52.33014256  93.59108657  80.23172167  63.62792384  81.76060756\n",
            "   88.8450535   67.63363723  46.44950671  75.64506402  81.02028788\n",
            "   83.89139849 102.90281651  79.69902394  71.96442641 110.45075287\n",
            "   63.74537769  81.9682295   76.87615986  65.4126782   75.97013981\n",
            "   95.86029213  95.90853866  73.54155883  79.44315546  67.35680797\n",
            "   78.61266769  67.40505451  78.01076264  71.47997521  69.30093775\n",
            "   87.2469603   83.70473733  84.86030089  95.6317094   99.10472506\n",
            "   66.87235677 106.83932259  73.54155883  86.20885058  54.9453847\n",
            "   82.43171992 100.84123289  77.15298912  79.30474083  88.29139498\n",
            "  100.37774247  77.89330879  69.95108933  82.94345687  98.10853691\n",
            "   45.47427934  69.07235502  53.00125492  83.42790807  65.82792209\n",
            "   68.93394039  73.86663462  89.35679045  58.21077841  74.95299087\n",
            "  110.45075287  48.99554153  95.46600903  68.2145815   96.90472681\n",
            "   64.39552927  82.3625126   76.27425481  90.09711013  85.6488671\n",
            "   84.30664238  69.16252312  81.22790982  68.95490117  89.28758314\n",
            "   56.5434779   70.87807016  89.42599777  78.23934537  84.97775474\n",
            "   92.91997421  90.90663712  42.92824452  75.76251786  92.89901342\n",
            "   79.76823125  41.70347364  73.70093424  57.65711989  70.02029664\n",
            "   85.57965979  57.12442216  35.84379858  71.47997521  45.6609405\n",
            "  101.85838183  72.47616336  55.87236553  87.91807266  90.18727823\n",
            "   85.44124516  41.19173669  78.23934537  83.42790807  73.07806841\n",
            "   72.68378531  72.61457799  63.05330454  21.55745284  72.61457799\n",
            "  101.69900641  79.58157009  74.16442466  83.28949344  65.08760241\n",
            "  111.05265792  52.86284029  76.01838634  44.59554504  91.83361796\n",
            "   69.14156233  66.94156409  92.89901342  82.94345687  75.55489592\n",
            "   80.55679746  52.35110335  55.20125317  76.87615986  82.43171992\n",
            "   94.98155783  82.89521034  58.97838383  55.68570437  66.75490293\n",
            "   82.34155182  85.23362321  75.94917902  80.41838283  62.86664338\n",
            "   62.33394565  54.59934812  50.84950321  88.49901693  68.53965729\n",
            "  103.98917276 102.18345762  72.54537068  53.78982113  75.55489592\n",
            "   71.52822174  77.61647954  52.65521835  88.10473382  95.37584093\n",
            "   61.47617212  96.39298987  63.88379232  93.84695504  85.23362321\n",
            "   83.49711538  80.7644194   86.368226    72.42791683  76.41266944\n",
            "   60.20315471  75.81076439  79.95489241  83.61456923  76.34346212\n",
            "   84.63171817  96.76631219  72.70474609  93.68757963  94.42789931\n",
            "   88.91426082  78.88949695  71.61838984  58.21077841 109.98726245\n",
            "   65.36443167  80.55679746  74.00504925  99.58917626  60.87426708\n",
            "   93.43171116  65.94537593 107.57964226  70.96823826  61.75300138\n",
            "   92.15869375 107.92567884  75.76251786  73.67997346  88.42980961\n",
            "   77.98347689  40.49966355 100.46791057  75.20885934 101.58155257\n",
            "   38.04379683  86.09139674  92.17965453  67.0107714   82.70854918\n",
            "   89.51616586  99.42980085  63.39934111  53.97648229  69.53584544\n",
            "   75.07044471  53.39553803  85.02600127  76.01838634  79.35298736\n",
            "   99.24313969  78.07996995  76.6894987   88.42980961  81.02028788\n",
            "   63.4203019   70.02029664  81.69140024  91.50854217 101.16630868\n",
            "   97.50663186  98.15678344  76.82791333  87.17775299  85.35107706\n",
            "   77.47806491  78.03172342  58.81268346  75.69331055  94.77393588\n",
            "   69.21076965  77.70664763  52.12252062  93.6393331   64.5339439\n",
            "   60.41077666  87.75869725  78.23934537  91.32188101  74.42029314\n",
            "  109.19869625  70.55299437  81.89902219  67.28760066  79.14536542\n",
            "   90.30473207  81.89902219  58.65330805  70.22791858  70.87807016\n",
            "  102.78536266 108.64503773  71.68759716  88.63743156  76.2050475\n",
            "   67.19743256  45.98601629  90.23552476 105.72568059  81.76060756\n",
            "   64.76252662  64.69331931  87.89711188  57.58791258  78.40504574\n",
            "  107.46218842  52.67617913  43.32252763  82.52188802 100.37774247\n",
            "   87.01837757  46.91299713  90.74726171  93.89520158  58.27998573\n",
            "   80.30092899  95.51425556 100.46791057  79.95489241  46.3802994\n",
            "   95.05076514  93.10663537  65.39171742 105.65647327  77.568233\n",
            "   89.70282702  96.69710487  59.41458851  83.4761546   70.13775049\n",
            "   62.19553102  78.61266769  82.22409797  67.0107714   52.19172793\n",
            "   92.17965453  50.060937    96.64885834  79.23553352  85.4685309\n",
            "   69.88188201  49.47999274  60.85330629  58.12061031  77.40885759\n",
            "   85.85648905  76.82791333  88.89330003  71.08569211  95.65267019\n",
            "   80.21076089  89.35679045  83.98156659  76.5993306   86.69330178\n",
            "   88.98346813  77.40885759  66.98981062  71.4107679   59.27617388\n",
            "   92.435523    66.40886635  82.15489066  79.95489241  79.51236278\n",
            "   90.09711013  53.92823576  88.63743156  59.99553277  85.35107706\n",
            "   90.83742981  75.97013981  67.93775224 105.4006048   97.97012228\n",
            "   76.98728874  78.21838458  91.39108832  60.5282305   61.87045523\n",
            "   76.22600828  45.70918703  68.00695955  67.42601529  64.74156584\n",
            "   77.01457449  79.49140199  92.98918152  86.43743331  82.3625126\n",
            "   84.61075738  64.5339439   60.94347439  50.33776626  89.49520508\n",
            "   46.05522361  72.33774873  49.59744658  92.57393763  63.3301338\n",
            "   90.90663712  75.0914055   72.73203184  87.22599952  54.27427233\n",
            "   71.20314595  86.83171641  89.28758314  81.55298561  63.93203885\n",
            "   58.65330805  66.6164883   81.06220945  33.8996688  110.79678945\n",
            "   75.16061281  91.92378606  60.87426708  52.79363298  94.10282352\n",
            "   71.73584369  48.78791959  75.60314245  93.84695504  89.49520508\n",
            "   91.13521985  95.28567283 103.26981387  91.50854217  87.17775299\n",
            "   79.62981662  62.07807717 103.38726771  71.36252137  77.22219643\n",
            "   70.34537243  84.70092548  85.28186974  73.61076614  53.18791608\n",
            "   76.82791333  90.09711013 106.9085299   51.24378631  88.49901693\n",
            "   91.04505175  68.40124266  97.90091497  73.61076614 100.67553252\n",
            "   55.40887512  73.28569035  82.80504224  82.29330529  82.50092723\n",
            "   69.69522085  69.69522085  65.13584894  76.6894987   81.34536367\n",
            "   90.85839059  69.21076965  80.2799682   62.00886986  92.17965453\n",
            "   81.02028788  72.03363373  85.69711363  49.25141001  76.62029138\n",
            "   67.68188376 113.46027811  66.38790557  80.67425131  68.35299613\n",
            "   69.48759891  93.57012579 101.58155257 112.25646802  79.07615811\n",
            "   76.50283754  90.0488636   85.88377479 105.05456823  70.41457974\n",
            "   74.76632971  75.55489592  68.88569386  70.08950396  82.01647603\n",
            "   88.56822424 105.05456823  80.7644194   98.41265192  61.06092824\n",
            "   83.68377654  91.97203259  44.04188652  79.09711889  74.69712239\n",
            "   78.42600653  40.56887086  82.24505876  61.7320406   75.22982013\n",
            "   88.03552651 107.53139573  90.76822249  88.31235577  88.58918503\n",
            "   54.41268696  92.0412399   92.17965453 102.5987015  102.30091146\n",
            "  111.65456297  79.8856851   85.42028437  93.77774773  73.61076614\n",
            "   60.1339474   72.47616336 106.86028337  67.42601529  98.62027386\n",
            "   75.69331055  76.48187675  82.77775649  76.75870601  93.50091847\n",
            "   96.85648028  81.02028788  98.36440538  66.87235677 103.73330429\n",
            "   89.42599777  60.75681323  94.89138973  73.47235151  87.10854567\n",
            "   72.26854142  69.48759891 109.73139398  78.88949695  85.09520858\n",
            "   53.46474534  68.44316423 103.3180604   69.46663812  68.88569386\n",
            "   64.11870001 106.53520758  44.24950846  97.50663186  88.56822424\n",
            "   68.28378881  67.54346913  82.75679571  74.09521735  85.69711363\n",
            "   99.36059354  89.97965628  60.1339474   73.77014156 108.66599851\n",
            "   80.95108056  56.937761   104.17583392  54.39172618  83.91235927\n",
            "  113.46027811  44.0628473  106.30662485  56.88951447  54.50918002\n",
            "   31.8171244   70.02029664  63.21267995  70.55299437  84.44505701\n",
            "   59.39362772  52.00506677  42.92824452 103.85075813  41.19173669\n",
            "   66.08379056  89.12188276  66.01458325  85.83552826 111.19107255\n",
            "   70.48378706  39.73205812 104.17583392  91.04505175  64.94918778\n",
            "   79.62981662  89.56441239  82.61838108  91.78537143  75.41648129\n",
            "   89.49520508 102.37011878  67.61267645  92.57393763  95.97774598\n",
            "   64.41649005  93.93712314  70.55299437  79.37394815  80.62600477\n",
            "   82.17585144  65.59933936  48.25522186  91.52950295  92.24886184\n",
            "   98.38536617  79.37394815  44.64379157  80.43934361  64.99743431\n",
            "   74.07425656  89.77203434  93.17584268 109.73139398  71.47997521\n",
            "  111.65456297  95.6317094   80.81266593  72.06091947  89.28758314\n",
            "  101.78917451  74.76632971  81.34536367  67.35680797  95.09901167\n",
            "   82.29330529  80.23172167  76.15680096  94.10282352  77.13202833\n",
            "   77.73393338  94.58727472  57.67808068  78.84125042  80.04506051\n",
            "   79.9758532   77.15298912  78.7720431   57.40125142  18.36126644\n",
            "   66.01458325 101.25647678  86.09139674  78.2875919   73.47235151\n",
            "   63.09522611  80.23172167  72.93965378  90.09711013  82.22409797\n",
            "   55.92061206  96.78727297  66.54728098  88.22218767  88.51997771\n",
            "   76.5993306   52.33014256  32.57840486  88.22218767  63.60696306\n",
            "   73.74918077  85.42028437 102.37011878  73.95680272  91.37012754\n",
            "   98.89710312  72.49712415  59.46283504 113.46027811  73.61076614\n",
            "   62.95681148  73.47235151  86.87996294  61.54537944  90.83742981\n",
            "   57.93394915  60.47998397  65.34347089  76.87615986  53.92823576\n",
            "   78.95870426  94.44886009  85.76632095  55.22221396  73.7974273\n",
            "  100.17012053  88.10473382  68.6088646   71.96442641  61.40696481\n",
            "  104.70853165  76.57204485  71.805051   106.39679295  69.37014506\n",
            "   67.4952226   83.82219117  90.16631744  72.93965378  60.01649355\n",
            "  113.46027811  60.15490818  59.87807893  77.22219643  96.8355195\n",
            "   74.33012504  95.44504824  89.17012929  68.95490117 102.90281651\n",
            "   85.6488671   77.10474259  74.48950045  85.558699    56.73013906\n",
            "   51.12633247  78.03172342  57.93394915  90.62980786 100.84123289\n",
            "   40.58983165  71.20314595  97.29900992 103.38726771  81.24887061\n",
            "   72.61457799  78.2875919   89.70282702  63.39934111  72.33774873\n",
            "   79.83743857  93.43171116  74.74536893  74.48950045  77.75489416\n",
            "   45.79935513  83.15107881  71.61838984  63.14347264  87.75869725\n",
            "   68.53965729  87.22599952  92.96822074  79.1663262   67.0107714\n",
            "   82.82600302 110.26409171 101.78917451  94.05457699  74.83553702\n",
            "   70.41457974  56.77838559  65.99362247  68.6990327   95.44504824\n",
            "   68.95490117  74.95299087  85.02600127  53.2571234   99.45076164\n",
            "   71.13393864  94.63552125  75.76251786  81.4837783   48.53205111\n",
            "   72.68378531  76.55108407  75.76251786  88.24314845  68.33203534\n",
            "   85.558699    78.70283579  95.37584093  59.99553277 104.72949244\n",
            "  109.59297935  51.45140825  48.67046574 100.72377905  94.82218241\n",
            "   84.21647428  62.07807717  92.85076689  90.62980786  76.94536717\n",
            "   50.57267395  69.88188201  71.4107679   77.15298912  51.61078367\n",
            "   74.81457624  65.68950746  92.71235226  87.50282878  82.52188802\n",
            "   81.43553177  62.67998222  92.71235226  62.38219218  71.75680447\n",
            "  101.85838183  88.17394114  43.5783961  106.65266143  59.18600578\n",
            "   81.36632445  92.96822074  88.15298035  71.73584369  89.97965628\n",
            "   94.63552125  77.36061106  79.56060931  79.67806315  70.43554053\n",
            "   92.98918152  68.07616687  53.6514065   67.19743256  92.85076689\n",
            "   49.85331506  63.60696306  63.69713116 101.78917451  97.04314144\n",
            "   68.2145815   76.87615986  71.75680447  65.66854668  84.23743506\n",
            "   88.42980961  90.97584443  83.15107881  74.88378355  78.35679921\n",
            "   74.95299087  77.61647954  80.62600477  69.02410849  99.12568585\n",
            "   75.16061281  86.48567984  84.7701328   57.28379757  76.36442291\n",
            "   69.48759891  91.37012754  90.30473207  78.14917727  95.77012403\n",
            "   91.6469568   56.47427058  81.15870251  70.2069578   73.47235151\n",
            "   89.88948818  74.35108582  67.82029839  72.61457799 100.121874\n",
            "   63.21267995  65.78600052 100.00442015  72.61457799  62.19553102\n",
            "   82.89521034  90.65076865  99.77583742  93.57012579  74.88378355]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "• To - Do - 3:\n",
        "1. Split the dataset into training and test sets.\n",
        "2. You can use an 80-20 or 70-30 split, with 80% (or 70%) of the data used for training and the rest\n",
        "for testing."
      ],
      "metadata": {
        "id": "vCouOftTURkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print shapes for verification\n",
        "print(\"\\nShapes after manual split (80-20):\")\n",
        "print(f\"X_train: {X_train.shape}, Y_train: {Y_train.shape}\")\n",
        "print(f\"X_test: {X_test.shape}, Y_test: {Y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJD8DNcNUTl7",
        "outputId": "95821a5b-486d-464e-d7f4-13b7f3fae748"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shapes after manual split (80-20):\n",
            "X_train: (80, 3), Y_train: (80,)\n",
            "X_test: (20, 3), Y_test: (20,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1.2 Step -2- Build a Cost Function:\n",
        "Cost function is the average of loss function measured across the data point. As the cost function for Regression\n",
        "problem we will be using Mean Square Error which is given by:\n",
        "\n",
        "L(w) = 1\n",
        "2n\n",
        "Xn\n",
        "i=1\n",
        "ypred(i) − yi\n",
        "2\n",
        "\n",
        "where:\n",
        "ypred(w) = WTX"
      ],
      "metadata": {
        "id": "OJzE6A0oXe9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_function(X, Y, W):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    X: Feature Matrix (d x n, where d is number of features, n is number of samples)\n",
        "    Y: Target Matrix (1 x n, where n is number of samples)\n",
        "    W: Weight Matrix (d x 1, where d is number of features)\n",
        "\n",
        "    Output:\n",
        "    cost: Accumulated mean square error\n",
        "    \"\"\"\n",
        "    n = len(Y) # no of clumns\n",
        "\n",
        "    # Reshape W to (d, 1) to make sure it can be multiplied with X\n",
        "    W = W.reshape(-1, 1)  # Shape: (2, 1)\n",
        "\n",
        "    # Predicted values: h_theta = X * W\n",
        "    y_pred = np.dot(X, W)  # Shape: (n, 1)\n",
        "\n",
        "    # Calculate the squared error: (y_pred - Y)^2\n",
        "    error = y_pred - Y.reshape(-1, 1)  # Reshape Y to (n, 1)\n",
        "    squared_error = np.square(error)  # Element-wise square, Shape: (n, 1)\n",
        "\n",
        "    # Mean Squared Error: (1 / (2n)) * sum(squared_error)\n",
        "    cost = (1 / (2 * n)) * np.sum(squared_error)\n",
        "\n",
        "    return cost"
      ],
      "metadata": {
        "id": "JuKoQVmmXfG4"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Designing a Test Case for Cost Function:\n",
        "\n",
        "We will first calculate the loss value manually and then verify the output via our code. If the computed value\n",
        "matches, we will proceed further."
      ],
      "metadata": {
        "id": "1K001MWLYSHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test case\n",
        "X_test = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "Y_test = np.array([3, 7, 11])\n",
        "W_test = np.array([1, 1])\n",
        "cost = cost_function(X_test, Y_test, W_test)\n",
        "if cost == 0:\n",
        "  print(\"Proceed Further\")\n",
        "else:\n",
        "  print(\"something went wrong: Reimplement a cost function\")\n",
        "print(\"Cost function output:\", cost_function(X_test, Y_test, W_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGIyI10yYcuc",
        "outputId": "59984521-fb33-4cd1-ef27-aa1ec57bd7c3"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proceed Further\n",
            "Cost function output: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1.3 Step -3- Gradient Descent for Simple Linear Regression:"
      ],
      "metadata": {
        "id": "x69CYVOYcTR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, Y, W, alpha, iterations):\n",
        "    \"\"\"\n",
        "    Perform gradient descent to optimize the parameters of a linear regression model.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): Feature matrix (m x d), where m is the number of samples, d is the number of features.\n",
        "    Y (numpy.ndarray): Target vector (m x 1).\n",
        "    W (numpy.ndarray): Initial guess for parameters (d x 1).\n",
        "    alpha (float): Learning rate.\n",
        "    iterations (int): Number of iterations for gradient descent.\n",
        "\n",
        "    Returns:\n",
        "    W_update (numpy.ndarray): Optimized parameters (d x 1).\n",
        "    cost_history (list): List of cost values over iterations.\n",
        "    \"\"\"\n",
        "    # Initialize cost history\n",
        "    cost_history = [0] * iterations\n",
        "\n",
        "    # Number of samples\n",
        "    m = len(Y)\n",
        "\n",
        "    for iteration in range(iterations):\n",
        "        # Step 1: Hypothesis Values (Y_pred)\n",
        "        Y_pred = np.dot(X, W)  # Shape: (m, 1)\n",
        "\n",
        "        # Step 2: Compute the loss (difference between predicted and actual)\n",
        "        loss = Y_pred - Y\n",
        "\n",
        "        # Step 3: Compute the gradient (dw)\n",
        "        dw = (1 / m) * np.dot(X.T, loss)  # Gradient (shape: d x 1)\n",
        "\n",
        "        # Step 4: Update the weights\n",
        "        W = W - alpha * dw  # Update rule\n",
        "\n",
        "        # Step 5: Calculate the new cost and store it\n",
        "        cost = cost_function(X, Y, W)  # Compute cost (MSE)\n",
        "        cost_history[iteration] = cost  # Store cost for this iteration\n",
        "\n",
        "    return W, cost_history"
      ],
      "metadata": {
        "id": "2aFnUQDza9OY"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Code for Gradient Descent function:"
      ],
      "metadata": {
        "id": "AUcOig9_csJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate random test data\n",
        "np.random.seed(0) # For reproducibility\n",
        "X = np.random.rand(100, 3) # 100 samples, 3 features\n",
        "Y = np.random.rand(100)\n",
        "W = np.random.rand(3) # Initial guess for parameters\n",
        "# Set hyperparameters\n",
        "alpha = 0.01\n",
        "iterations = 1000\n",
        "# Test the gradient_descent function\n",
        "final_params, cost_history = gradient_descent(X, Y, W, alpha, iterations)\n",
        "# Print the final parameters and cost history\n",
        "print(\"Final Parameters:\", final_params)\n",
        "print(\"Cost History:\", cost_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5A6CgUzcsRM",
        "outputId": "fcbe24a3-af00-489e-8385-96f9fcdbaef8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Parameters: [0.20551667 0.54295081 0.10388027]\n",
            "Cost History: [0.10711197094660153, 0.10634880599939901, 0.10559826315680618, 0.10486012948320558, 0.1041341956428534, 0.10342025583900626, 0.1027181077540776, 0.1020275524908062, 0.10134839451441931, 0.1006804415957737, 0.1000235047554587, 0.09937739820884377, 0.09874193931205609, 0.09811694850887098, 0.09750224927850094, 0.0968976680842672, 0.09630303432313951, 0.09571818027612913, 0.09514294105952065, 0.09457715457692842, 0.09402066147216397, 0.09347330508290017, 0.09293493139511913, 0.09240538899833017, 0.09188452904154543, 0.0913722051899995, 0.09086827358260123, 0.09037259279010502, 0.08988502377398919, 0.08940542984603007, 0.08893367662855953, 0.08846963201539432, 0.08801316613342668, 0.08756415130486386, 0.08712246201010665, 0.08668797485125508, 0.08626056851623207, 0.08584012374351278, 0.08542652328745133, 0.08501965188419301, 0.0846193962181636, 0.08422564488912489, 0.08383828837978763, 0.08345721902397185, 0.08308233097530582, 0.08271352017645425, 0.08235068432886682, 0.08199372286303817, 0.08164253690927113, 0.08129702926893387, 0.08095710438620353, 0.08062266832028739, 0.08029362871811391, 0.07996989478748553, 0.0796513772706855, 0.07933798841853089, 0.07902964196486459, 0.07872625310147845, 0.07842773845346054, 0.07813401605495938, 0.0778450053253578, 0.0775606270458499, 0.07728080333641404, 0.07700545763317514, 0.07673451466614989, 0.07646790043736812, 0.07620554219936448, 0.07594736843403344, 0.07569330883184205, 0.07544329427139428, 0.07519725679934074, 0.07495512961062821, 0.07471684702908327, 0.07448234448832412, 0.0742515585129952, 0.07402442670031911, 0.0738008877019607, 0.07358088120619749, 0.0733643479203919, 0.07315122955375959, 0.07294146880042966, 0.07273500932279067, 0.07253179573511871, 0.07233177358748233, 0.0721348893499193, 0.07194109039688139, 0.07175032499194182, 0.07156254227276149, 0.07137769223630935, 0.07119572572433286, 0.07101659440907385, 0.07084025077922623, 0.070666648126131, 0.07049574053020462, 0.07032748284759716, 0.07016183069707572, 0.0699987404471299, 0.06983816920329523, 0.06968007479569092, 0.06952441576676843, 0.06937115135926715, 0.06922024150437375, 0.06907164681008185, 0.06892532854974835, 0.0687812486508435, 0.06863936968389095, 0.06849965485159508, 0.06836206797815195, 0.06822657349874123, 0.06809313644919561, 0.067961722455845, 0.06783229772553254, 0.06770482903579932, 0.06757928372523506, 0.06745562968399212, 0.06733383534445969, 0.06721386967209597, 0.06709570215641501, 0.06697930280212627, 0.06686464212042395, 0.06675169112042348, 0.0666404213007429, 0.06653080464122665, 0.06642281359480932, 0.06631642107951677, 0.06621160047060279, 0.06610832559281864, 0.06600657071281309, 0.0659063105316614, 0.06580752017752023, 0.06571017519840698, 0.06561425155510119, 0.06551972561416586, 0.06542657414108709, 0.06533477429352925, 0.06524430361470467, 0.06515514002685512, 0.06506726182484374, 0.06498064766985515, 0.06489527658320228, 0.06481112794023773, 0.06472818146436811, 0.0646464172211699, 0.06456581561260431, 0.06448635737133043, 0.0644080235551142, 0.06433079554133217, 0.06425465502156798, 0.06417958399630046, 0.06410556476968135, 0.06403257994440141, 0.0639606124166433, 0.06388964537111992, 0.06381966227619645, 0.06375064687909507, 0.06368258320118077, 0.06361545553332655, 0.06354924843135755, 0.06348394671157162, 0.06341953544633615, 0.06335599995975896, 0.06329332582343267, 0.06323149885225086, 0.06317050510029515, 0.06311033085679153, 0.06305096264213547, 0.06299238720398384, 0.0629345915134133, 0.06287756276114324, 0.06282128835382297, 0.0627657559103815, 0.06271095325843898, 0.06265686843077901, 0.06260348966188053, 0.06255080538450809, 0.06249880422636036, 0.06244747500677472, 0.06239680673348793, 0.06234678859945137, 0.06229740997970036, 0.0622486604282762, 0.06220052967520031, 0.062153007623499706, 0.062106084346282515, 0.062059750083863094, 0.06201399524093575, 0.06196881038379625, 0.061924186237610215, 0.06188011368372787, 0.0618365837570441, 0.06179358764340313, 0.061751116677047156, 0.06170916233810801, 0.0616677162501414, 0.06162677017770278, 0.061586316023964055, 0.0615463458283708, 0.06150685176433905, 0.06146782613699094, 0.0614292613809287, 0.061391150058046254, 0.06135348485537795, 0.06131625858298352, 0.061279464171868706, 0.06124309467194143, 0.061207143250002184, 0.06117160318776841, 0.06113646787993252, 0.061101730832252524, 0.06106738565967507, 0.06103342608449018, 0.06099984593451716, 0.06096663914132128, 0.0609337997384604, 0.0609013218597616, 0.06086919973762659, 0.06083742770136588, 0.06080600017556133, 0.06077491167845612, 0.06074415682037193, 0.06071373030215326, 0.060683626913637524, 0.06065384153215141, 0.06062436912103256, 0.0605952047281761, 0.06056634348460599, 0.060537780603070336, 0.060509511376660545, 0.0604815311774538, 0.060453835455178496, 0.06042641973590228, 0.06039927962074216, 0.060372410784596583, 0.060345808974898815, 0.06031947001039151, 0.06029338977992186, 0.06026756424125725, 0.060241989419920934, 0.06021666140804729, 0.0601915763632565, 0.06016673050754826, 0.060142120126214255, 0.06011774156676883, 0.06009359123789796, 0.06006966560842588, 0.06004596120629915, 0.060022474617588105, 0.059999202485504784, 0.059976141509438, 0.05995328844400421, 0.05993064009811483, 0.05990819333405906, 0.059885945066602345, 0.059863892262100066, 0.059842031937626106, 0.059820361160116395, 0.05979887704552664, 0.05977757675800453, 0.05975645750907579, 0.05973551655684408, 0.0597147512052044, 0.05969415880306974, 0.05967373674361096, 0.05965348246350928, 0.05963339344222168, 0.059613467201258485, 0.059593701303473294, 0.05957409335236496, 0.05955464099139111, 0.05953534190329372, 0.059516193809435625, 0.0594971944691485, 0.0594783416790919, 0.05945963327262296, 0.0594410671191769, 0.05942264112365792, 0.05940435322584049, 0.059386201399780576, 0.059368183653237094, 0.059350298027102844, 0.05933254259484533, 0.05931491546195686, 0.05929741476541398, 0.0592800386731462, 0.05926278538351338, 0.05924565312479226, 0.05922864015467154, 0.059211744759755505, 0.059194965255076046, 0.05917829998361292, 0.05916174731582212, 0.059145305649172315, 0.059128973407688926, 0.059112749041506096, 0.05909663102642617, 0.05908061786348662, 0.059064708078534194, 0.05904890022180654, 0.05903319286752055, 0.05901758461346795, 0.05900207408061755, 0.058986659912724324, 0.05897134077594505, 0.058956115358460404, 0.05894098237010357, 0.05892594054199501, 0.05891098862618344, 0.05889612539529293, 0.05888134964217589, 0.05886666017957195, 0.058852055839772675, 0.05883753547429179, 0.058823097953541174, 0.058808742166512155, 0.05879446702046235, 0.058780271440607684, 0.05876615436981961, 0.05875211476832761, 0.05873815161342641, 0.05872426389918856, 0.058710450636181515, 0.05869671085118971, 0.058683043586941104, 0.058669447901838714, 0.05865592286969638, 0.05864246757947903, 0.05862908113504752, 0.05861576265490756, 0.058602511271963004, 0.05858932613327336, 0.058576206399815284, 0.05856315124624814, 0.05855015986068357, 0.05853723144445888, 0.05852436521191438, 0.05851156039017436, 0.0584988162189318, 0.05848613195023677, 0.05847350684828838, 0.058460940189230176, 0.05844843126094919, 0.05843597936287807, 0.05842358380580092, 0.05841124391166213, 0.05839895901337858, 0.05838672845465502, 0.05837455158980245, 0.05836242778355972, 0.05835035641091811, 0.05833833685694878, 0.05832636851663321, 0.05831445079469655, 0.05830258310544367, 0.05829076487259809, 0.05827899552914358, 0.05826727451716845, 0.058255601287712386, 0.0582439753006161, 0.058232396024373266, 0.05822086293598511, 0.058209375520817355, 0.058197933272459756, 0.05818653569258779, 0.05817518229082684, 0.058163872584618616, 0.05815260609908985, 0.058141382366923164, 0.058130200928230166, 0.058119061330426776, 0.058107963128110396, 0.05809690588293942, 0.058085889163514745, 0.058074912545263056, 0.058063975610322414, 0.058053077947429504, 0.05804221915180897, 0.05803139882506447, 0.05802061657507169, 0.0580098720158732, 0.05799916476757483, 0.057988494456244134, 0.057977860713810364, 0.057967263177966154, 0.05795670149207094, 0.05794617530505593, 0.05793568427133074, 0.057925228050691516, 0.057914806308230836, 0.057904418714248757, 0.057894064944165734, 0.05788374467843681, 0.05787345760246728, 0.057863203406529826, 0.05785298178568306, 0.05784279243969133, 0.057832635072946004, 0.05782250939438805, 0.0578124151174319, 0.05780235195989063, 0.057792319643902336, 0.05778231789585793, 0.0577723464463298, 0.05776240503000217, 0.05775249338560223, 0.05774261125583255, 0.05773275838730474, 0.05772293453047407, 0.05771313943957533, 0.0577033728725597, 0.057693634591032654, 0.057683924360193005, 0.05767424194877295, 0.05766458712897906, 0.05765495967643434, 0.057645359370121226, 0.05763578599232564, 0.057626239328581796, 0.05761671916761811, 0.05760722530130401, 0.05759775752459752, 0.057588315635493874, 0.057578899434974906, 0.05756950872695933, 0.05756014331825381, 0.05755080301850501, 0.057541487640152184, 0.05753219699838088, 0.057522930911077144, 0.057513689198782685, 0.05750447168465076, 0.05749527819440267, 0.057486108556285255, 0.05747696260102877, 0.05746784016180581, 0.05745874107419066, 0.05744966517611951, 0.05744061230785123, 0.05743158231192885, 0.05742257503314173, 0.057413590318488285, 0.05740462801713937, 0.057395687980402336, 0.05738677006168561, 0.05737787411646401, 0.057369000002244354, 0.05736014757853204, 0.05735131670679789, 0.057342507250445686, 0.05733371907478018, 0.05732495204697581, 0.057316206036045626, 0.05730748091281111, 0.057298776549872255, 0.05729009282157824, 0.05728142960399854, 0.05727278677489465, 0.05726416421369212, 0.05725556180145319, 0.05724697942084986, 0.0572384169561373, 0.05722987429312795, 0.05722135131916572, 0.05721284792310103, 0.05720436399526589, 0.0571958994274496, 0.057187454112874896, 0.05717902794617434, 0.05717062082336728, 0.057162232641836994, 0.05715386330030848, 0.05714551269882637, 0.05713718073873334, 0.05712886732264895, 0.05712057235444866, 0.05711229573924336, 0.05710403738335914, 0.0570957971943175, 0.05708757508081579, 0.057079370952708035, 0.057071184720986066, 0.05706301629776107, 0.057054865596245175, 0.057046732530733744, 0.05703861701658757, 0.05703051897021566, 0.05702243830905818, 0.057014374951569684, 0.057006328817202634, 0.05699829982639134, 0.05699028790053585, 0.05698229296198646, 0.05697431493402824, 0.05696635374086599, 0.05695840930760929, 0.056950481560257914, 0.0569425704256875, 0.0569346758316353, 0.05692679770668645, 0.05691893598026014, 0.05691109058259633, 0.05690326144474244, 0.05689544849854041, 0.056887651676613984, 0.05687987091235604, 0.056872106139916355, 0.05686435729418944, 0.05685662431080263, 0.0568489071261043, 0.05684120567715239, 0.056833519901703065, 0.05682584973819958, 0.05681819512576124, 0.05681055600417275, 0.056802932313873525, 0.056795323995947306, 0.056787730992111936, 0.05678015324470926, 0.05677259069669528, 0.05676504329163035, 0.05675751097366966, 0.05674999368755382, 0.05674249137859953, 0.05673500399269066, 0.05672753147626912, 0.056720073776326194, 0.05671263084039382, 0.056705202616536096, 0.05669778905334098, 0.05669039009991206, 0.05668300570586036, 0.05667563582129657, 0.056668280396823104, 0.05666093938352648, 0.05665361273296975, 0.056646300397185066, 0.05663900232866641, 0.05663171848036241, 0.05662444880566923, 0.05661719325842369, 0.056609951792896414, 0.05660272436378514, 0.05659551092620811, 0.056588311435697584, 0.05658112584819342, 0.05657395412003692, 0.05656679620796451, 0.05655965206910184, 0.05655252166095763, 0.05654540494141801, 0.056538301868740586, 0.05653121240154893, 0.056524136498826864, 0.056517074119913024, 0.05651002522449555, 0.05650298977260663, 0.05649596772461748, 0.056488959041233064, 0.05648196368348717, 0.05647498161273735, 0.0564680127906601, 0.056461057179246134, 0.05645411474079556, 0.05644718543791332, 0.05644026923350467, 0.056433366090770515, 0.05642647597320331, 0.05641959884458242, 0.05641273466897008, 0.05640588341070717, 0.05639904503440896, 0.05639221950496121, 0.05638540678751615, 0.05637860684748858, 0.056371819650551894, 0.05636504516263454, 0.05635828334991603, 0.05635153417882347, 0.05634479761602789, 0.05633807362844066, 0.05633136218321008, 0.056324663247717996, 0.05631797678957624, 0.05631130277662355, 0.05630464117692215, 0.056297991958754665, 0.05629135509062089, 0.056284730541234666, 0.05627811827952098, 0.05627151827461283, 0.0562649304958483, 0.05625835491276777, 0.05625179149511093, 0.05624524021281401, 0.05623870103600713, 0.05623217393501149, 0.05622565888033667, 0.05621915584267811, 0.05621266479291449, 0.056206185702105234, 0.05619971854148787, 0.05619326328247578, 0.05618681989665565, 0.05618038835578517, 0.05617396863179063, 0.05616756069676472, 0.05616116452296419, 0.05615478008280768, 0.05614840734887347, 0.05614204629389748, 0.05613569689077096, 0.0561293591125386, 0.056123032932396344, 0.05611671832368947, 0.05611041525991056, 0.05610412371469758, 0.056097843661832, 0.05609157507523687, 0.05608531792897493, 0.05607907219724691, 0.056072837854389615, 0.05606661487487427, 0.05606040323330473, 0.056054202904415734, 0.05604801386307135, 0.056041836084263226, 0.056035669543109, 0.056029514214850695, 0.05602337007485319, 0.05601723709860266, 0.05601111526170498, 0.05600500453988435, 0.05599890490898177, 0.05599281634495359, 0.055986738823870105, 0.055980672321914095, 0.055974616815379595, 0.055968572280670384, 0.055962538694298715, 0.05595651603288404, 0.05595050427315166, 0.0559445033919315, 0.05593851336615685, 0.05593253417286313, 0.05592656578918666, 0.05592060819236354, 0.05591466135972839, 0.05590872526871329, 0.05590279989684662, 0.05589688522175184, 0.055890981221146614, 0.05588508787284151, 0.055879205154739084, 0.05587333304483278, 0.05586747152120588, 0.055861620562030555, 0.05585578014556684, 0.05584995025016163, 0.05584413085424776, 0.05583832193634303, 0.0558325234750493, 0.0558267354490515, 0.05582095783711688, 0.05581519061809395, 0.05580943377091164, 0.055803687274578614, 0.05579795110818212, 0.05579222525088745, 0.055786509681936956, 0.05578080438064925, 0.05577510932641848, 0.05576942449871346, 0.055763749877076975, 0.05575808544112503, 0.05575243117054599, 0.05574678704509999, 0.05574115304461813, 0.055735529149001775, 0.05572991533822185, 0.0557243115923182, 0.05571871789139883, 0.05571313421563932, 0.05570756054528211, 0.055701996860635865, 0.055696443142074864, 0.055690899370038335, 0.05568536552502988, 0.05567984158761686, 0.055674327538429685, 0.05566882335816142, 0.055663329027567085, 0.055657844527463085, 0.05565236983872668, 0.05564690494229538, 0.0556414498191665, 0.05563600445039652, 0.055630568817100635, 0.05562514290045211, 0.05561972668168197, 0.05561432014207832, 0.05560892326298588, 0.055603536025805575, 0.055598158411993996, 0.05559279040306291, 0.055587431980578784, 0.055582083126162425, 0.05557674382148841, 0.055571414048284674, 0.05556609378833211, 0.055560783023464094, 0.05555548173556606, 0.055550189906575106, 0.05554490751847952, 0.055539634553318486, 0.05553437099318153, 0.055529116820208266, 0.05552387201658793, 0.055518636564558965, 0.05551341044640875, 0.05550819364447313, 0.05550298614113609, 0.05549778791882936, 0.05549259896003212, 0.05548741924727061, 0.05548224876311773, 0.055477087490192804, 0.0554719354111612, 0.055466792508733924, 0.05546165876566746, 0.055456534164763226, 0.05545141868886745, 0.05544631232087083, 0.05544121504370806, 0.055436126840357744, 0.055431047693841926, 0.05542597758722593, 0.055420916503617974, 0.05541586442616892, 0.055410821338071965, 0.05540578722256242, 0.05540076206291734, 0.055395745842455345, 0.05539073854453634, 0.05538574015256118, 0.05538075064997147, 0.055375770020249314, 0.05537079824691705, 0.05536583531353694, 0.05536088120371103, 0.05535593590108084, 0.05535099938932713, 0.055346071652169704, 0.0553411526733671, 0.05533624243671647, 0.05533134092605322, 0.055326448125250914, 0.05532156401822096, 0.05531668858891247, 0.055311821821311946, 0.055306963699443185, 0.05530211420736701, 0.055297273329180996, 0.05529244104901939, 0.0552876173510529, 0.05528280221948834, 0.05527799563856866, 0.055273197592572584, 0.05526840806581448, 0.055263627042644155, 0.055258854507446706, 0.05525409044464235, 0.05524933483868614, 0.05524458767406786, 0.05523984893531189, 0.055235118606976955, 0.05523039667365596, 0.05522568311997589, 0.055220977930597534, 0.055216281090215466, 0.05521159258355773, 0.055206912395385714, 0.055202240510494154, 0.05519757691371069, 0.055192921589895944, 0.055188274523943294, 0.05518363570077869, 0.05517900510536053, 0.05517438272267951, 0.055169768537758505, 0.055165162535652366, 0.055160564701447826, 0.05515597502026334, 0.055151393477248956, 0.05514682005758613, 0.055142254746487665, 0.05513769752919755, 0.0551331483909908, 0.055128607317173346, 0.055124074293081866, 0.055119549304083755, 0.05511503233557687, 0.05511052337298953, 0.05510602240178027, 0.05510152940743782, 0.05509704437548093, 0.05509256729145828, 0.05508809814094827, 0.05508363690955906, 0.05507918358292834, 0.05507473814672324, 0.055070300586640204, 0.05506587088840496, 0.05506144903777225, 0.05505703502052585, 0.055052628822478474, 0.05504823042947156, 0.05504383982737522, 0.05503945700208816, 0.05503508193953754, 0.055030714625678864, 0.05502635504649593, 0.05502200318800065, 0.055017659036233034, 0.055013322577261034, 0.055008993797180404, 0.05500467268211479, 0.05500035921821539, 0.054996053391661005, 0.05499175518865794, 0.05498746459543984, 0.054983181598267664, 0.0549789061834296, 0.054974638337240846, 0.05497037804604376, 0.0549661252962075, 0.054961880074128146, 0.0549576423662285, 0.054953412158958034, 0.054949189438792796, 0.05494497419223534, 0.05494076640581463, 0.05493656606608597, 0.05493237315963089, 0.05492818767305708, 0.05492400959299837, 0.05491983890611449, 0.05491567559909121, 0.05491151965864005, 0.05490737107149833, 0.05490322982442909, 0.054899095904220915, 0.05489496929768798, 0.05489084999166989, 0.05488673797303166, 0.054882633228663574, 0.05487853574548118, 0.054874445510425175, 0.05487036251046136, 0.054866286732580524, 0.05486221816379847, 0.05485815679115577, 0.0548541026017179, 0.054850055582575, 0.05484601572084191, 0.0548419830036581, 0.05483795741818747, 0.05483393895161846, 0.0548299275911639, 0.054825923324060916, 0.05482192613757092, 0.05481793601897949, 0.05481395295559637, 0.05480997693475535, 0.05480600794381422, 0.0548020459701547, 0.054798091001182415, 0.05479414302432678, 0.054790202027040935, 0.05478626799680179, 0.05478234092110976, 0.05477842078748891, 0.0547745075834868, 0.054770601296674395, 0.05476670191464608, 0.05476280942501958, 0.054758923815435796, 0.05475504507355896, 0.05475117318707636, 0.0547473081436984, 0.05474344993115854, 0.054739598537213205, 0.054735753949641676, 0.05473191615624621, 0.05472808514485178, 0.054724260903306156, 0.05472044341947975, 0.05471663268126573, 0.05471282867657969, 0.0547090313933599, 0.05470524081956701, 0.05470145694318413, 0.05469767975221677, 0.054693909234692674, 0.05469014537866194, 0.05468638817219683, 0.05468263760339178, 0.05467889366036329, 0.05467515633125, 0.05467142560421251, 0.05466770146743334, 0.054663983909116975, 0.054660272917489705, 0.05465656848079964, 0.05465287058731666, 0.05464917922533233, 0.05464549438315985, 0.054641816049134054, 0.05463814421161133, 0.05463447885896955, 0.05463081997960807, 0.05462716756194763, 0.05462352159443039, 0.054619882065519716, 0.054616248963700355, 0.05461262227747823, 0.05460900199538041, 0.054605388105955124, 0.054601780597771675, 0.05459817945942039, 0.05459458467951261, 0.05459099624668059, 0.05458741414957748, 0.0545838383768773, 0.054580268917274875, 0.05457670575948582, 0.05457314889224635, 0.054569598304313474, 0.0545660539844648, 0.054562515921498494, 0.05455898410423328, 0.054555458521508345, 0.05455193916218337, 0.05454842601513845, 0.05454491906927401, 0.05454141831351079, 0.054537923736789846, 0.054534435328072464, 0.0545309530763401, 0.054527476970594374, 0.054524006999857044, 0.054520543153169884, 0.05451708541959473, 0.054513633788213396, 0.054510188248127645, 0.05450674878845912, 0.05450331539834934, 0.054499888066959656, 0.05449646678347117, 0.054493051537084725, 0.05448964231702087, 0.05448623911251984, 0.05448284191284145, 0.054479450707265106, 0.05447606548508972, 0.054472686235633755, 0.054469312948235114, 0.0544659456122511, 0.05446258421705838, 0.05445922875205301, 0.05445587920665035, 0.05445253557028493, 0.05444919783241064, 0.05444586598250044, 0.054442540010046496, 0.05443921990456002, 0.0544359056555714, 0.054432597252629965, 0.05442929468530409, 0.054425997943181044, 0.05442270701586708, 0.05441942189298729, 0.05441614256418564, 0.05441286901912488, 0.05440960124748651, 0.054406339238970806, 0.05440308298329671, 0.054399832470201845, 0.054396587689442416, 0.054393348630793245, 0.05439011528404767, 0.05438688763901759, 0.054383665685533336, 0.0543804494134437, 0.054377238812615865, 0.05437403387293539, 0.054370834584306166, 0.05436764093665037, 0.054364452919908414, 0.05436127052403898, 0.05435809373901896, 0.05435492255484332]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1.4 Step -4- Evaluate the Model:\n",
        "\n",
        "Evaluation in Machine Learning measures the goodness of fit of your build model. Lets see How Good is\n",
        "model we designed above, as discussed in the class for regression we can use following function as evaluation\n",
        "measure.\n",
        "1. Root Mean Square Error:"
      ],
      "metadata": {
        "id": "ck96GXAhcyGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(Y, Y_pred):\n",
        "    \"\"\"\n",
        "    This function calculates the Root Mean Squared Error (RMSE).\n",
        "\n",
        "    Parameters:\n",
        "    Y (numpy.ndarray): Array of actual target values (n,).\n",
        "    Y_pred (numpy.ndarray): Array of predicted values (n,).\n",
        "\n",
        "    Returns:\n",
        "    float: The RMSE value.\n",
        "    \"\"\"\n",
        "    # Calculate the squared differences\n",
        "    squared_errors = (Y - Y_pred) ** 2\n",
        "\n",
        "    # Calculate the mean of squared errors\n",
        "    mean_squared_error = np.mean(squared_errors)\n",
        "\n",
        "    # Take the square root of the mean squared error\n",
        "    rmse_value = np.sqrt(mean_squared_error)\n",
        "\n",
        "    return rmse_value"
      ],
      "metadata": {
        "id": "pLpsEEcMc2oc"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. R2 or Coefficient of Determination:"
      ],
      "metadata": {
        "id": "_h6obEt4daOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def r2(Y, Y_pred):\n",
        "    \"\"\"\n",
        "    This function calculates the R-Squared (R²) value.\n",
        "\n",
        "    Parameters:\n",
        "    Y (numpy.ndarray): Array of actual target values (n,).\n",
        "    Y_pred (numpy.ndarray): Array of predicted values (n,).\n",
        "\n",
        "    Returns:\n",
        "    float: R-Squared (R²) value.\n",
        "    \"\"\"\n",
        "    # Step 1: Calculate the mean of actual values (ȳ)\n",
        "    mean_y = np.mean(Y)\n",
        "\n",
        "    # Step 2: Compute the Total Sum of Squares (SST)\n",
        "    ss_tot = np.sum((Y - mean_y) ** 2)\n",
        "\n",
        "    # Step 3: Compute the Sum of Squared Residuals (SSR)\n",
        "    ss_res = np.sum((Y - Y_pred) ** 2)\n",
        "\n",
        "    # Step 4: Calculate R-Squared (R²)\n",
        "    r2 = 1 - (ss_res / ss_tot)\n",
        "\n",
        "    return r2"
      ],
      "metadata": {
        "id": "RVPvByzjda0V"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1.5 Step -5- Main Function to Integrate All Steps:\n",
        "\n",
        "In this section, we will create a main function that integrates the data loading, preprocessing, cost function,\n",
        "gradient descent, and model evaluation. This will help in running the entire workflow with minimal effort.\n",
        "\n",
        "• Objective:\n",
        "\n",
        "The objective of the main function is to execute the full process, from loading the data to performing\n",
        "linear regression using gradient descent and evaluating the results using metrics like RMSE and R2\n",
        ".\n",
        "\n",
        "• To - Do:\n",
        "We will define a function that:\n",
        "1. Loads the data and splits it into training and test sets.\n",
        "2. Prepares the feature matrix (X) and target vector (Y).\n",
        "3. Defines the weight matrix (W) and initializes the learning rate and number of iterations.\n",
        "4. Calls the gradient descent function to learn the parameters.\n",
        "5. Evaluates the model using RMSE and R2"
      ],
      "metadata": {
        "id": "rGbEpVfod-Lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def main():\n",
        "  # Step 1: Load the dataset\n",
        "  data= pd.read_csv('/content/drive/MyDrive/AI/Resources/Week5/student.csv')\n",
        "  # Step 2: Split the data into features (X) and target (Y)\n",
        "  X = data[['Math', 'Reading']].values # Features: Math and Reading marks\n",
        "  Y = data['Writing'].values # Target: Writing marks\n",
        "  # Step 3: Split the data into training and test sets (80% train, 20% test)\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "  # Step 4: Initialize weights (W) to zeros, learning rate and number of iterations\n",
        "  W = np.zeros(X_train.shape[1]) # Initialize weights\n",
        "  alpha = 0.00001 # Learning rate\n",
        "  iterations = 1000 # Number of iterations for gradient descent\n",
        "  # Step 5: Perform Gradient Descent\n",
        "  W_optimal, cost_history = gradient_descent(X_train, Y_train, W, alpha, iterations)\n",
        "  # Step 6: Make predictions on the test set\n",
        "  Y_pred = np.dot(X_test, W_optimal)\n",
        "  # Step 7: Evaluate the model using RMSE and R-Squared\n",
        "  model_rmse = rmse(Y_test, Y_pred)\n",
        "  model_r2 = r2(Y_test, Y_pred)\n",
        "  # Step 8: Output the results\n",
        "  print(\"Final Weights:\", W_optimal)\n",
        "  print(\"Cost History (First 10 iterations):\", cost_history[:10])\n",
        "  print(\"RMSE on Test Set:\", model_rmse)\n",
        "  print(\"R-Squared on Test Set:\", model_r2)\n",
        "\n",
        "# Execute the main function\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2hi-gCXezD0",
        "outputId": "9c4f7cfc-dec0-4772-e64e-d63ff016ea50"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Weights: [0.34811659 0.64614558]\n",
            "Cost History (First 10 iterations): [2013.165570783755, 1640.286832599692, 1337.0619994901588, 1090.4794892850578, 889.9583270083234, 726.8940993009545, 594.2897260808594, 486.4552052951635, 398.7634463599484, 327.4517147324688]\n",
            "RMSE on Test Set: 5.2798239764188635\n",
            "R-Squared on Test Set: 0.8886354462786421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model's performance is acceptable. It has a high R-squared value (0.89), indicating that it explains most of the variance in the target variable, and the RMSE is reasonable (5.28). This suggests the model is neither overfitting nor underfitting, but rather providing good predictions on the test set."
      ],
      "metadata": {
        "id": "iysgQXuiggxp"
      }
    }
  ]
}